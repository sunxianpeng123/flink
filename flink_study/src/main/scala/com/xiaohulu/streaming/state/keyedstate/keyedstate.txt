1、Managed State和Raw State
    首先区分一下两个概念，state一般指一个具体的task/operator的状态。而checkpoint则表示了一个Flink Job，在一个特定时刻的一份全局状态快照，即包含了所有task/operator的状态。
    所谓checkpoint，就是在某一时刻，将所有task的状态做一个快照(snapshot)，然后存储到memory/file system/rocksdb等。Flink通过定期地做checkpoint来实现容错和恢复。
   a、 Flink有两种基本类型的状态：托管状态（Managed State）和原生状态（Raw State）。从名称中也能读出两者的区别：Managed State是由Flink管理的，Flink帮忙存储、恢复和优化，Raw State是开发者自己管理的，需要自己序列化。
   b、state：一般指一个具体的task/operator的状态。State可以被记录，在失败的情况下数据还可以恢复，Flink中有两种基本类型的State：Keyed State，Operator State，它们两种都可以以两种形式存在：原始状态(raw state)和托管状态(managed state)
   c、托管状态：由Flink框架管理的状态，我们通常使用的就是这种。
   d、原始状态：由用户自行管理状态具体的数据结构，框架在做checkpoint的时候，使用byte[]来读写状态内容，对其内部数据结构一无所知。通常在DataStream上的状态推荐使用托管的状态，当实现一个用户自定义的operator时，会使用到原始状态。
              可是我们使用Flink的时候，基本是不会自定义状态的。
   e、Apache Flink 内部按照算子和数据分组角度将State划分为如下两类：
      KeyState：keyed state 记录的是每个key的状态，Keyed state托管状态有六种类型
            ValueState MapState ListState ReducingState AggregatingState FoldingState
      OperatorState：里面没有shuffle操作的state
            ListState UnionListState BroadcastState
            operator state是task级别的state，说白了就是每个task对应一个state
            operator state 只有一种托管状态：ValueState
2、Managed State
    （1）Keyed State和Operator State
       a、 Keyed State是KeyedStream上的状态。假如输入流按照id为Key进行了keyBy分组，形成一个KeyedStream，数据流中所有id为1的数据共享一个状态，可以访问和更新这个状态，以此类推，每个Key对应一个自己的状态

       b、 Operator State可以用在所有算子上，每个算子子任务或者说每个算子实例共享一个状态，流入这个算子子任务的数据可以访问和更新这个状态。

       c、无论是Keyed State还是Operator State，Flink的状态都是基于本地的，即每个算子子任务维护着这个算子子任务对应的状态存储，算子子任务之间的状态不能相互访问。

                                Keyed State	                                        Operator State
        适用算子类型	    只适用于KeyedStream上的算子	                            可以用于所有算子
        状态分配	        每个Key对应一个状态	                                    一个算子子任务对应一个状态
        创建和访问方式	    重写Rich Function，通过里面的RuntimeContext访问	        实现CheckpointedFunction等接口
        横向扩展	        状态随着Key自动在多个算子子任务上迁移	                有多种状态重新分配的方式
        支持的数据结构	    ValueState、ListState、MapState等	                    ListState、BroadcastState等

3、横向扩展问题
            状态的横向扩展问题主要是指修改Flink应用的并行度，确切的说，每个算子的并行实例数或算子子任务数发生了变化，应用需要关停或启动一些算子子任务，某份在原来某个算子子任务上的状态数据需要平滑更新到新的算子子任务上。
        其实，Flink的Checkpoint就是一个非常好的在各算子间迁移状态数据的机制。算子的本地状态将数据生成快照（snapshot），保存到分布式存储（如HDFS）上。横向伸缩后，算子子任务个数变化，子任务重启，相应的状态从分布式存储上重建（restore）。

4、Keyed State的使用方法
        对于Keyed State，Flink提供了几种现成的数据结构供我们使用，包括ValueState、ListState等，他们的继承关系如下图所示。

    （1）首先，State主要有三种实现，分别为ValueState、MapState和AppendingState，AppendingState又可以细分为ListState、ReducingState和AggregatingState。

    （2）这几个状态的具体区别在于：
        a、ValueState[T]是单一变量的状态，T是某种具体的数据类型，比如Double、String，或我们自己定义的复杂数据结构。我们可以使用value()方法获取状态，使用update(value: T)更新状态。
        b、MapState[K, V]存储一个Key-Value map，其功能与Java的Map几乎相同。
                    get(key: K)可以获取某个key下的value，
                    put(key: K, value: V)可以对某个key设置value，
                    contains(key: K)判断某个key是否存在，
                    remove(key: K)删除某个key以及对应的value，
                    entries(): java.lang.Iterable[java.util.Map.Entry[K, V]]返回MapState中所有的元素，
                    iterator(): java.util.Iterator[java.util.Map.Entry[K, V]]返回一个迭代器。
                    需要注意的是，MapState中的key和Keyed State的key不是同一个key。
        c、ListState[T]存储了一个由T类型数据组成的列表。我们可以使用
                    add(value: T)或addAll(values: java.util.List[T])向状态中添加元素，
                    使用get(): java.lang.Iterable[T]获取整个列表，
                    使用update(values: java.util.List[T])来更新列表，新的列表将替换旧的列表。
        d、ReducingState[T]和AggregatingState[IN, OUT]与ListState[T]同属于MergingState[T]。
                    与ListState[T]不同的是，
                    ReducingState[T]只有一个元素，而不是一个列表。它的原理是新元素通过add(value: T)加入后，与已有的状态元素使用ReduceFunction合并为一个元素，并更新到状态里。
                    AggregatingState[IN, OUT]与ReducingState[T]类似，也只有一个元素，只不过AggregatingState[IN, OUT]的输入和输出类型可以不一样。
                    ReducingState[T]和AggregatingState[IN, OUT]与窗口上进行ReduceFunction和AggregateFunction很像，都是将新元素与已有元素做聚合。

5、注意，Flink的核心代码目前使用Java实现的，而Java的很多类型与Scala的类型不太相同，比如List和Map。这里不再详细解释Java和Scala的数据类型的异同，但是开发者在使用Scala调用这些接口，比如状态的接口，需要注意将Java的类型转为Scala的类型。
        对于List和Map的转换，只需要需要引用import scala.collection.JavaConversions._，并在必要的地方添加后缀asScala或asJava来进行转换。此外，Scala和Java的空对象使用习惯不太相同，Java一般使用null表示空，Scala一般使用None。

6、state生命周期
      override def open(parameters: Configuration): Unit = {
        val stateTtlConfig = StateTtlConfig
    //      指定ttl时间为10秒
          .newBuilder(Time.seconds(10))
    //      指定ttl刷新时只对创建和写入操作有效
          .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
    //      指定状态可见性为永远不返回过期数据
          .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired).build()

        val descriptor = new ListStateDescriptor[(Long, Long)]("average", createTypeInformation[(Long, Long)])
        descriptor.enableTimeToLive(stateTtlConfig)
        elementByKey = getRuntimeContext.getListState(descriptor)
      }0











