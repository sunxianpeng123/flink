# parquet repartition number
data_repartition_num=200
# partition num of insert mysql
insert_mysql_num=50

## local or online
where_to_run=local
#app name
spark_app_name=anchor_dy_live_schedule
#used to group for multi group by
group_num=20

# mysql write
dbIpW=113.107.166.14
dbUserW=xiangjia
dbPasswordW=p1B6((5R41Hny7Hd
dbPassportW=25149

#parquet read
anchor_basic_info_path=hdfs://192.168.120.160/user/spark/parquet/live_show/anchor_basic_info
fans_list_path=hdfs://192.168.120.160//user/spark/parquet/live_show/fans_list_info/
fans_info_path=hdfs://192.168.120.160//user/spark/parquet/live_show/fans_info/
goods_info_path=hdfs://192.168.120.160//user/spark/parquet/live_show/goods_info/
#
maxOnlineView_percent=1.38
sn_add_percent=60
item_type=4,5,6,7

#read vip or not ,1 read vip, 0 not read vip
is_read_db_vip=1

#es config
es.ip=110.43.48.145
es.port=9200
es.mapping.date.rich =false
es.internal.spark.sql.pushdown.strict=true
es.nodes.wan.only=true
es.scroll.size=50
es.input.max.docs.per.partition=1000
#es index
dy_anchor_index=scene_basic
dy_goods_index=scene_goods_infos
svip_url=http://121.10.141.53:9995/api/v1/douyin/online/svip/view?level=1




