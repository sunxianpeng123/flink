#kafka topics \uFFFD\uFFFDconnect with ","
anchor_basic_info_topics=crawler-data-scene-basic-71
fans_info_topics=crawler-data-scene-fans-info-71
fans_list_topics=crawler-data-scene-tyrant_rank-71
anchor_goods_topics=crawler-data-scene-goods-infos-71
purchase_intention_topics=crawler-data-scene-purchase-intention-71
# kafka topics of taobao
taobao_live_info_topics=crawler-data-scene-live-info-73
taobao_goods_info_topics=crawler-data-scene-goods-info-73
# kafka topics of kuaishou
kuaishou_live_info_topics=crawler-data-scene-live-info-59
kuaishou_goods_info_topics=crawler-data-scene-goods-info-59


#kafka consumer  test_stream_qa_20190708
KafkaGroupId=kaifa_dy_live_20200617
#kafka server
brokers=Kafka-01:9092

#default value is 5
streaming_minutes_interval=5
#spark task name
spark_app_name=stream_sv_2parquet

# where to run ,value is online ...
where_to_run=local

#parquet write path
# config like : 'hdfs://192.168.120.160/tmp/spark/parquet/anchor_live_schedule/gift'
anchor_basic_info_path=user/spark/parquet/live_show/anchor_basic_info/
fans_info_path=user/spark/parquet/live_show/fans_info/
fans_list_path=user/spark/parquet/live_show/fans_list_info/
goods_info_path=user/spark/parquet/live_show/goods_info/
purchase_intention_path=user/spark/parquet/live_show/purchase_info/
# write path of taobao data
tb_anchor_basic_info_path=user/spark/parquet/live_show/anchor_basic_info_tb/
tb_goods_info_path=user/spark/parquet/live_show/goods_info_tb/
# write path of kuaishou data
ks_anchor_basic_info_path=user/spark/parquet/live_show/anchor_basic_info_ks/
ks_goods_info_path=user/spark/parquet/live_show/goods_info_ks/


#kafka config
#platIDS=1001,2,3,4,5,6,7,8,9,13,15,20,21,29,57
#platIDS=15


